{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzFV_20OfZ61"
   },
   "source": [
    "# LSTM in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkCY1KUffZ62",
    "outputId": "d450282b-ae85-4c17-ca31-572efc0ee96a"
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YliMhgiYfZ63"
   },
   "source": [
    "## Basic LSTM in Pytorch with random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OfuTrln0fZ63"
   },
   "outputs": [],
   "source": [
    "#input\n",
    "x = torch.tensor([[1,2, 12,34, 56,78, 90,80],\n",
    "                 [12,45, 99,67, 6,23, 77,82],\n",
    "                 [3,24, 6,99, 12,56, 21,22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_AP3JuEge1P",
    "outputId": "9f400b87-893f-47ce-f144-b23a0268ad26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP008BTrfZ63"
   },
   "source": [
    "#### using two different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VVm3Nj5yfZ63"
   },
   "outputs": [],
   "source": [
    "model1 = nn.Embedding(100, 7, padding_idx=0)\n",
    "model2 = nn.LSTM(input_size=7, hidden_size=3, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8v959Oj1f5o8",
    "outputId": "09940fe6-d495-48d6-bccc-1afa09be9c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(100, 7, padding_idx=0)\n",
      "weight torch.Size([100, 7])\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "for name, param in model1.named_parameters():\n",
    "    print (name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YoVXwev_fZ63"
   },
   "outputs": [],
   "source": [
    "out1 = model1(x)\n",
    "out2 = model2(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doJoI-UnlQv4",
    "outputId": "56cf7a1f-80e7-4386-f203-1b970dca816a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(7, 3, batch_first=True)\n",
      "weight_ih_l0 torch.Size([12, 7])\n",
      "weight_hh_l0 torch.Size([12, 3])\n",
      "bias_ih_l0 torch.Size([12])\n",
      "bias_hh_l0 torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "print(model2)\n",
    "for name, param in model2.named_parameters():\n",
    "    print (name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XA_8tmpDfZ64",
    "outputId": "9c778398-f453-4606-e5c2-b222e73507e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 7])\n",
      "tensor([[[ 1.0901, -0.1593,  0.6650,  0.2456,  0.3406, -1.3329,  0.6954],\n",
      "         [ 0.3798,  0.5201,  0.1932,  1.1549,  0.0685, -0.7466, -0.2904],\n",
      "         [-0.6632,  1.4525, -0.1910,  0.4362,  0.5490, -1.6861,  1.6541],\n",
      "         [ 1.5351, -0.7867, -0.4847, -0.0082, -0.6175, -0.5503, -0.2015],\n",
      "         [-1.5917,  0.4777,  0.3365, -0.5456, -0.3524,  0.9582,  1.1184],\n",
      "         [ 0.8526, -1.0249,  0.1919, -1.9348,  0.8062, -0.0530, -0.1203],\n",
      "         [-0.4034,  1.5814, -0.4121,  1.4274,  0.6267, -0.1648,  0.3458],\n",
      "         [-0.1021, -0.2201,  0.7095,  0.1200, -3.0810,  0.7647, -0.1864]],\n",
      "\n",
      "        [[-0.6632,  1.4525, -0.1910,  0.4362,  0.5490, -1.6861,  1.6541],\n",
      "         [-0.2482, -1.8267,  0.7440, -0.9848, -0.6675,  0.6528, -0.5892],\n",
      "         [ 1.8834,  1.0524,  0.9729,  0.5428,  0.4874,  0.5897, -0.9407],\n",
      "         [-0.0559,  1.2702,  0.0935, -1.0264,  0.1006,  1.0052, -0.2658],\n",
      "         [ 0.7261, -1.0326, -1.8372,  2.1531, -0.4839,  1.7049,  0.3869],\n",
      "         [-0.0120, -1.5172,  0.4036, -0.2990,  0.9270, -1.3133, -0.9885],\n",
      "         [-0.7273, -1.4241,  0.6009,  0.0897, -1.2713, -0.8046, -0.3322],\n",
      "         [-0.6837,  1.4360, -1.2104, -0.6820,  0.5094,  0.2492,  1.3464]],\n",
      "\n",
      "        [[-1.6326, -0.2186,  0.3017,  0.5480,  0.5510,  0.4959,  0.9808],\n",
      "         [ 0.0329,  0.4414, -0.1717, -0.9788, -1.5891, -0.6457,  0.4807],\n",
      "         [ 0.7261, -1.0326, -1.8372,  2.1531, -0.4839,  1.7049,  0.3869],\n",
      "         [ 1.8834,  1.0524,  0.9729,  0.5428,  0.4874,  0.5897, -0.9407],\n",
      "         [-0.6632,  1.4525, -0.1910,  0.4362,  0.5490, -1.6861,  1.6541],\n",
      "         [-1.5917,  0.4777,  0.3365, -0.5456, -0.3524,  0.9582,  1.1184],\n",
      "         [ 0.2046,  1.3687, -0.5540, -0.8384,  0.1333,  0.2637, -2.5719],\n",
      "         [-0.3672, -0.3455,  0.4530,  0.3659,  0.7844,  0.8906, -0.2339]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out1.shape)\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_yLZvG2ianV",
    "outputId": "deb5f9ca-16b1-4733-c980-cc882e46ba30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWq3aSMyfZ64",
    "outputId": "b5769d36-219e-4768-e05d-cd8a2284ea29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "out, (ht, ct) = model2(out1)\n",
    "print(ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1KlE3U-i4W3",
    "outputId": "315a7bfd-dbf5-4f92-f2d3-ff2c85ccb9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 3])\n",
      "torch.Size([1, 3, 3])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(ht.shape)\n",
    "print(ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUcdk0IoNhaB",
    "outputId": "9386ef04-90e2-4a1f-fad9-fcb89be88d8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0359,  0.0102,  0.3304],\n",
      "         [-0.0726, -0.0199,  0.2845],\n",
      "         [-0.0528, -0.0963,  0.4883],\n",
      "         [-0.1604,  0.0295,  0.4522],\n",
      "         [ 0.0797, -0.0154,  0.3148],\n",
      "         [ 0.4156, -0.0356,  0.2419],\n",
      "         [ 0.2728, -0.0817,  0.2443],\n",
      "         [ 0.0333,  0.0397,  0.2731]],\n",
      "\n",
      "        [[ 0.0080, -0.1103,  0.3283],\n",
      "         [ 0.1577, -0.0756,  0.3162],\n",
      "         [ 0.0252, -0.0298,  0.1012],\n",
      "         [ 0.1188, -0.0686,  0.0190],\n",
      "         [-0.0015,  0.0803,  0.0512],\n",
      "         [ 0.0831, -0.0361,  0.2573],\n",
      "         [ 0.0801, -0.2291,  0.5756],\n",
      "         [ 0.3401, -0.0572,  0.2958]],\n",
      "\n",
      "        [[ 0.1622, -0.0333,  0.0864],\n",
      "         [-0.0161, -0.2400,  0.2744],\n",
      "         [-0.0327,  0.0672,  0.2472],\n",
      "         [-0.0866,  0.1174,  0.0610],\n",
      "         [-0.1790, -0.0513,  0.3716],\n",
      "         [ 0.1584, -0.0326,  0.2205],\n",
      "         [ 0.0134, -0.3732,  0.0160],\n",
      "         [ 0.1165, -0.1066,  0.0177]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.0333,  0.0397,  0.2731],\n",
      "         [ 0.3401, -0.0572,  0.2958],\n",
      "         [ 0.1165, -0.1066,  0.0177]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dplLcYyEfZ64"
   },
   "source": [
    "#### using nn.sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bO4qwcUDfZ64"
   },
   "outputs": [],
   "source": [
    "model3 = nn.Sequential(nn.Embedding(100, 7, padding_idx=0),\n",
    "                        nn.LSTM(input_size=7, hidden_size=3, num_layers=1, batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozjgrDf-m_H8",
    "outputId": "bb66bcd6-dcd7-4cf3-a812-a04e3d99f93c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Embedding(100, 7, padding_idx=0)\n",
      "  (1): LSTM(7, 3, batch_first=True)\n",
      ")\n",
      "0.weight torch.Size([100, 7])\n",
      "1.weight_ih_l0 torch.Size([12, 7])\n",
      "1.weight_hh_l0 torch.Size([12, 3])\n",
      "1.bias_ih_l0 torch.Size([12])\n",
      "1.bias_hh_l0 torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "print(model3)\n",
    "for name, param in model3.named_parameters():\n",
    "    print (name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etMrJI5SfZ65",
    "outputId": "c1fd9113-0d00-4bbd-c001-401f44ed4fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-4.2407e-02, -2.3003e-02, -3.0795e-01],\n",
      "         [-5.3531e-02, -6.1740e-02, -2.5085e-01],\n",
      "         [-3.4837e-02, -4.7687e-02, -2.3117e-01],\n",
      "         [-5.1555e-04,  1.3455e-01, -2.2131e-01],\n",
      "         [ 1.5301e-01,  3.5757e-01, -2.7589e-01],\n",
      "         [ 5.1307e-02,  1.1507e-02, -2.0547e-01],\n",
      "         [ 7.4796e-02,  2.1338e-02, -1.9023e-01],\n",
      "         [-4.2027e-03, -1.1740e-02, -1.1846e-01]],\n",
      "\n",
      "        [[-1.1426e-02,  2.2446e-02,  6.9458e-04],\n",
      "         [ 5.5026e-02, -4.5224e-02, -6.1695e-02],\n",
      "         [ 6.1524e-02,  1.3966e-01, -3.3928e-01],\n",
      "         [ 3.1143e-02,  2.7456e-01, -1.0514e-01],\n",
      "         [ 8.5409e-02,  1.3588e-01, -3.1427e-01],\n",
      "         [ 1.7498e-01,  1.9168e-01, -2.5169e-01],\n",
      "         [ 1.4623e-01,  1.8034e-01, -8.6848e-02],\n",
      "         [ 6.9871e-02,  2.4040e-02, -6.4555e-02]],\n",
      "\n",
      "        [[ 1.2535e-01,  5.7884e-02,  1.7001e-02],\n",
      "         [ 3.8908e-02,  1.2217e-01, -3.1478e-01],\n",
      "         [ 6.7457e-02,  9.7066e-02, -3.9773e-01],\n",
      "         [ 9.5190e-02,  1.7204e-01, -5.2000e-01],\n",
      "         [ 1.0620e-01,  1.3993e-01, -2.5828e-01],\n",
      "         [ 1.9425e-01,  3.5966e-01, -2.8741e-01],\n",
      "         [ 1.0220e-01,  4.8423e-01,  1.9729e-01],\n",
      "         [ 2.7021e-02,  1.7816e-01,  1.1504e-01]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out, (ht, ct) = model3(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1jZx3yUnNvf",
    "outputId": "2588617b-8a32-47c9-b73c-4dbc36b04f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 3])\n",
      "torch.Size([1, 3, 3])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(ht.shape)\n",
    "print(ct.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma6AmTBsfZ65"
   },
   "source": [
    "## Multiclass Text Classification\n",
    "\n",
    "We are going to predict item ratings based on customer reviews bsed on this dataset from Kaggle:\n",
    "https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyGy_mCkOBX8",
    "outputId": "7572a53e-922d-4958-9358-d8760758eb26"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "XmGSB3yEfZ65",
    "outputId": "29193239-f405-431a-b4a4-325864196b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This book was very informative, covering all a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am already a baseball fan and knew a bit abo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I didn't like this product it smudged all unde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I simply love the product. I appreciate print ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It goes on very easily and makes my eyes look ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  ratings\n",
       "0           0  This book was very informative, covering all a...        4\n",
       "1           1  I am already a baseball fan and knew a bit abo...        5\n",
       "2           2  I didn't like this product it smudged all unde...        1\n",
       "3           3  I simply love the product. I appreciate print ...        5\n",
       "4           4  It goes on very easily and makes my eyes look ...        5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data\n",
    "# reviews = pd.read_csv(\"/content/drive/MyDrive/data/NLP_sentiment_analysis_data/train.csv\")\n",
    "reviews = pd.read_csv(\"train.csv\")\n",
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "d3uldQiTfZ65"
   },
   "outputs": [],
   "source": [
    "# reviews['Title'] = reviews['Title'].fillna('')\n",
    "# reviews['Review Text'] = reviews['Review Text'].fillna('')\n",
    "# reviews['review'] = reviews['Title'] + ' ' + reviews['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Oh60NcTwfZ65",
    "outputId": "018f219a-18b5-4ebb-ed91-c1c1c49814d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This book was very informative, covering all a...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am already a baseball fan and knew a bit abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn't like this product it smudged all unde...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I simply love the product. I appreciate print ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It goes on very easily and makes my eyes look ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  review_length\n",
       "0  This book was very informative, covering all a...        4             10\n",
       "1  I am already a baseball fan and knew a bit abo...        5             23\n",
       "2  I didn't like this product it smudged all unde...        1             14\n",
       "3  I simply love the product. I appreciate print ...        5             13\n",
       "4  It goes on very easily and makes my eyes look ...        5             13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping only relevant columns and calculating sentence lengths\n",
    "reviews = reviews[['reviews', 'ratings']]\n",
    "reviews.columns = ['reviews', 'ratings']\n",
    "reviews['review_length'] = reviews['reviews'].apply(lambda x: len(x.split()))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "TvsOZQR8fZ66",
    "outputId": "718a39ce-9af3-4e10-f8d8-da2fdb2d3a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This book was very informative, covering all a...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am already a baseball fan and knew a bit abo...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn't like this product it smudged all unde...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I simply love the product. I appreciate print ...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It goes on very easily and makes my eyes look ...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  review_length\n",
       "0  This book was very informative, covering all a...        3             10\n",
       "1  I am already a baseball fan and knew a bit abo...        4             23\n",
       "2  I didn't like this product it smudged all unde...        0             14\n",
       "3  I simply love the product. I appreciate print ...        4             13\n",
       "4  It goes on very easily and makes my eyes look ...        4             13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing ratings to 0-numbering\n",
    "zero_numbering = {1:0, 2:1, 3:2, 4:3, 5:4}\n",
    "reviews['ratings'] = reviews['ratings'].apply(lambda x: zero_numbering[x])\n",
    "print(type(reviews['ratings']))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-BYV0shfZ66",
    "outputId": "348fa896-b057-42f9-c561-38bb5ab093f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.58756"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean sentence length\n",
    "np.mean(reviews['review_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "uPS7xmtFfZ66"
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "# tok = spacy.load('en')\n",
    "tok = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "mEJZH5iufZ66"
   },
   "outputs": [],
   "source": [
    "# #count number of occurences of each word\n",
    "# counts = Counter()\n",
    "# for index, row in reviews.iterrows():\n",
    "#     if index%1000==0:\n",
    "#       print(index)\n",
    "#     counts.update(tokenize(row['reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NcVjtiS-UsrR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# with open('/content/drive/MyDrive/data/NLP_sentiment_analysis_data/count.pickle', 'wb') as outputfile:\n",
    "#   pickle.dump(counts,outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dkuyLk3DVbYf"
   },
   "outputs": [],
   "source": [
    "# with open('/content/drive/MyDrive/data/NLP_sentiment_analysis_data/count.pickle', 'rb') as inputfile:\n",
    "#   counts=pickle.load(inputfile)\n",
    "with open('count.pickle', 'rb') as inputfile:\n",
    "  counts=pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-QcG10alfZ67"
   },
   "outputs": [],
   "source": [
    "# #deleting infrequent words\n",
    "# print(\"num_words before:\",len(counts.keys()))\n",
    "# for word in list(counts):\n",
    "#     if counts[word] < 2:\n",
    "#         del counts[word]\n",
    "# print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SgUuFwYtfZ67"
   },
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "SOunom1cfZ67"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "#     encoded = [0]*N\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     enc1 = [vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized]\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQuzQnOTfZ67",
    "outputId": "3b4b0635-a89f-4c41-ebfd-7bca7d4c4f69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|██████████| 50000/50000 [00:03<00:00, 12977.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>review_length</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This book was very informative, covering all a...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am already a baseball fan and knew a bit abo...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>[[13, 14, 15, 16, 17, 18, 19, 20, 16, 21, 22, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn't like this product it smudged all unde...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[[13, 31, 32, 33, 2, 34, 35, 36, 9, 37, 38, 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I simply love the product. I appreciate print ...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>[[13, 42, 43, 23, 34, 7, 13, 44, 45, 46, 47, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It goes on very easily and makes my eyes look ...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>[[35, 50, 51, 5, 52, 19, 53, 38, 39, 54, 55, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  review_length  \\\n",
       "0  This book was very informative, covering all a...        3             10   \n",
       "1  I am already a baseball fan and knew a bit abo...        4             23   \n",
       "2  I didn't like this product it smudged all unde...        0             14   \n",
       "3  I simply love the product. I appreciate print ...        4             13   \n",
       "4  It goes on very easily and makes my eyes look ...        4             13   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0, 0,...  \n",
       "1  [[13, 14, 15, 16, 17, 18, 19, 20, 16, 21, 22, ...  \n",
       "2  [[13, 31, 32, 33, 2, 34, 35, 36, 9, 37, 38, 39...  \n",
       "3  [[13, 42, 43, 23, 34, 7, 13, 44, 45, 46, 47, 4...  \n",
       "4  [[35, 50, 51, 5, 52, 19, 53, 38, 39, 54, 55, 1...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews['encoded'] = reviews['reviews'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "\n",
    "reviews['encoded'] = reviews['reviews'].progress_apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "print(type(reviews['encoded']))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Q-6e2lbHfZ67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 6871, 4: 33193, 0: 4059, 1: 2265, 2: 3612})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how balanced the dataset is\n",
    "Counter(reviews['ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-IGQyguYfZ68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "X = list(reviews['encoded'])\n",
    "y = list(reviews['ratings'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMdT7QojfZ68"
   },
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vZaB3HMGfZ68"
   },
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0]), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "BAU_1-vsfZ68"
   },
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qjbgdFN-fZ68"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat.detach().cpu(), y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred.cpu() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred.cpu(), y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "pyTzIuRhfZ69"
   },
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "camjvpj5fZ69"
   },
   "source": [
    "### LSTM with fixed length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "mW_KX2DifZ69"
   },
   "outputs": [],
   "source": [
    "class LSTM_fixed_len(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "a_2Z2kQkfZ69"
   },
   "outputs": [],
   "source": [
    "model_fixed =  LSTM_fixed_len(vocab_size, 50, 50)\n",
    "model_fixed=model_fixed.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "25O6McgKfZ69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.094, val loss 1.086, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fixed, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "QXaGEkPbfZ6-"
   },
   "outputs": [],
   "source": [
    "def test_model (model, test_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in test_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat.detach().cpu(), y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        pred=pred.cpu()\n",
    "        test_acc=accuracy_score(y,pred)\n",
    "        test_recall_score=recall_score(y,pred,average='weighted')\n",
    "        test_precision_score=precision_score(y,pred,average='weighted')\n",
    "        test_f1_score=f1_score(y,pred,average='weighted')\n",
    "        test_confusion_matrix=confusion_matrix(y,pred)\n",
    "                \n",
    "        print(\" Test accuracy is \"+str(test_acc))\n",
    "        print(\" test_recall_score is \"+str(test_recall_score))\n",
    "        print(\" test_precision_score is \"+str(test_precision_score))\n",
    "        print(\" test_f1_score is \"+str(test_f1_score))\n",
    "        print(test_confusion_matrix)\n",
    "    return\n",
    "            \n",
    "#         correct += (pred.cpu() == y).float().sum()\n",
    "#         total += y.shape[0]\n",
    "#         sum_loss += loss.item()*y.shape[0]\n",
    "#         sum_rmse += np.sqrt(mean_squared_error(pred.cpu(), y.unsqueeze(-1)))*y.shape[0]\n",
    "#     return sum_loss/total, correct/total, sum_rmse/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = pd.read_csv(\"gold_test.csv\")\n",
    "test_reviews = test_reviews[['reviews', 'ratings']]\n",
    "test_reviews.columns = ['reviews', 'ratings']\n",
    "# print(len(test_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5200.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy is 0.5784\n",
      " test_recall_score is 0.5784\n",
      " test_precision_score is 0.33454656\n",
      " test_f1_score is 0.42390593005575267\n",
      "[[   0    0    0    0 1271]\n",
      " [   0    0    0    0  630]\n",
      " [   0    0    0    0  911]\n",
      " [   0    0    0    0 1404]\n",
      " [   0    0    0    0 5784]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_batch=len(test_reviews)\n",
    "test_reviews['ratings'] = test_reviews['ratings'].apply(lambda x: zero_numbering[x])\n",
    "test_reviews['encoded'] = test_reviews['reviews'].progress_apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "X_test = list(test_reviews['encoded'])\n",
    "y_test = list(test_reviews['ratings'])\n",
    "test_ds = ReviewsDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=test_batch)\n",
    "test_model(model_fixed, test_dl)\n",
    "\n",
    "# test_loss, test_acc, test_rmse = test_model(model_fixed, test_dl)\n",
    "# print(\" test loss %.3f, test accuracy %.3f, and test rmse %.3f\" % (test_loss, test_acc, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3de3lNbGfZ6-"
   },
   "outputs": [],
   "source": [
    "train_model(model_fixed, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHAn7853fZ6-"
   },
   "source": [
    "### LSTM with variable length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "0xJc7mnqfZ6-"
   },
   "outputs": [],
   "source": [
    "class LSTM_variable_input(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "95VEOBFTfZ6-"
   },
   "outputs": [],
   "source": [
    "model = LSTM_variable_input(vocab_size, 50, 50)\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "BtTe3FeRfZ6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.028, val loss 0.990, val accuracy 0.672, and val rmse 1.397\n",
      "train loss 0.698, val loss 0.804, val accuracy 0.715, and val rmse 1.030\n",
      "train loss 0.624, val loss 0.775, val accuracy 0.715, and val rmse 0.945\n",
      "train loss 0.592, val loss 0.781, val accuracy 0.719, and val rmse 0.933\n",
      "train loss 0.581, val loss 0.787, val accuracy 0.718, and val rmse 0.932\n",
      "train loss 0.566, val loss 0.787, val accuracy 0.723, and val rmse 0.941\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Lm9JzHoXfZ6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy is 0.6642\n",
      " test_recall_score is 0.6642\n",
      " test_precision_score is 0.6202604795344706\n",
      " test_f1_score is 0.6368367907781483\n",
      "[[ 776  137  126   57  175]\n",
      " [ 228   98  111   67  126]\n",
      " [ 185   90  221  186  229]\n",
      " [  73   27  166  291  847]\n",
      " [ 106   36  104  282 5256]]\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "JrbPoxS_fZ6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.552, val loss 0.786, val accuracy 0.722, and val rmse 0.918\n",
      "train loss 0.528, val loss 0.790, val accuracy 0.724, and val rmse 0.921\n",
      "train loss 0.515, val loss 0.788, val accuracy 0.723, and val rmse 0.913\n",
      "train loss 0.502, val loss 0.804, val accuracy 0.722, and val rmse 0.908\n",
      "train loss 0.495, val loss 0.805, val accuracy 0.723, and val rmse 0.921\n",
      "train loss 0.493, val loss 0.805, val accuracy 0.722, and val rmse 0.925\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy is 0.6585\n",
      " test_recall_score is 0.6585\n",
      " test_precision_score is 0.6277692002131692\n",
      " test_f1_score is 0.640291551685078\n",
      "[[ 759  153  161   47  151]\n",
      " [ 191  105  150   75  109]\n",
      " [ 139  111  268  188  205]\n",
      " [  56   44  203  303  798]\n",
      " [  75   47  150  362 5150]]\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0vwSEkqfZ6_"
   },
   "source": [
    "### LSTM with pretrained Glove word embeddings\n",
    "\n",
    "Download weights from : https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "9TbTKuQbfZ6_"
   },
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file=\"./glove.6B.50d.txt\"):\n",
    "    \"\"\"Load the glove word vectors\"\"\"\n",
    "    word_vectors = {}\n",
    "    with open(glove_file) as f:\n",
    "        for line in f:\n",
    "            split = line.split()\n",
    "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "zFcawkCufZ6_"
   },
   "outputs": [],
   "source": [
    "def get_emb_matrix(pretrained, word_counts, emb_size = 50):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_counts) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_counts:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "HQyp9tT4fZ7A"
   },
   "outputs": [],
   "source": [
    "word_vecs = load_glove_vectors()\n",
    "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "Sbthr4KPfZ7A"
   },
   "outputs": [],
   "source": [
    "class LSTM_glove_vecs(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "l8f14VNMfZ7A"
   },
   "outputs": [],
   "source": [
    "model_glove = LSTM_glove_vecs(vocab_size, 50, 50, pretrained_weights)\n",
    "model_glove=model_glove.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "jac3UBRmfZ7A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.084, val loss 1.080, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.078, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.080, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n"
     ]
    }
   ],
   "source": [
    "train_model(model_glove, epochs=30, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy is 0.5784\n",
      " test_recall_score is 0.5784\n",
      " test_precision_score is 0.33454656\n",
      " test_f1_score is 0.42390593005575267\n",
      "[[   0    0    0    0 1271]\n",
      " [   0    0    0    0  630]\n",
      " [   0    0    0    0  911]\n",
      " [   0    0    0    0 1404]\n",
      " [   0    0    0    0 5784]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_model(model_glove, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Bqis_8uAfZ7A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.079, val loss 1.080, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.080, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.080, val accuracy 0.663, and val rmse 1.462\n",
      "train loss 1.079, val loss 1.079, val accuracy 0.663, and val rmse 1.462\n"
     ]
    }
   ],
   "source": [
    "train_model(model_glove, epochs=30, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "w1FtEb-ofZ7B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy is 0.5784\n",
      " test_recall_score is 0.5784\n",
      " test_precision_score is 0.33454656\n",
      " test_f1_score is 0.42390593005575267\n",
      "[[   0    0    0    0 1271]\n",
      " [   0    0    0    0  630]\n",
      " [   0    0    0    0  911]\n",
      " [   0    0    0    0 1404]\n",
      " [   0    0    0    0 5784]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_model(model_glove, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zwshu8rfZ7B"
   },
   "source": [
    "## Predicting ratings using regression instead of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xRWaqlIfZ7B"
   },
   "outputs": [],
   "source": [
    "def train_model_regr(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.float()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.mse_loss(y_pred, y.unsqueeze(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss = validation_metrics_regr(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train mse %.3f val rmse %.3f\" % (sum_loss/total, val_loss))\n",
    "\n",
    "def validation_metrics_regr (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.float()\n",
    "        y_hat = model(x, l)\n",
    "        loss = np.sqrt(F.mse_loss(y_hat, y.unsqueeze(-1)).item())\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz2NRpsqfZ7B"
   },
   "outputs": [],
   "source": [
    "class LSTM_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJ3VKMLmfZ7B"
   },
   "outputs": [],
   "source": [
    "model =  LSTM_regr(vocab_size, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUDDwpzCfZ7B"
   },
   "outputs": [],
   "source": [
    "train_model_regr(model, epochs=30, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrs2eBs1fZ7D"
   },
   "outputs": [],
   "source": [
    "train_model_regr(model, epochs=30, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgpiIWIIfZ7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rE31SD0ffZ7E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YMdT7QojfZ68",
    "camjvpj5fZ69",
    "aHAn7853fZ6-",
    "z0vwSEkqfZ6_"
   ],
   "name": "LSTM_multiclass_text_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
